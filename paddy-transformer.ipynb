{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":35325,"databundleVersionId":3359805,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\n\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport timm\nfrom sklearn.model_selection import train_test_split\n\n# Configuration\nclass Config:\n    DATA_PATH = '../input/paddy-disease-classification'  # Kaggle dataset path\n    TRAIN_PATH = f'{DATA_PATH}/train_images'\n    TEST_PATH = f'{DATA_PATH}/test_images'\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    NUM_CLASSES = 15\n    IMAGE_SIZE = 224\n    BATCH_SIZE = 32\n    EPOCHS = 20\n    LEARNING_RATE = 2e-4\n    WEIGHT_DECAY = 1e-4\n\n# Dataset class\nclass PaddyDataset(Dataset):\n    def __init__(self, image_paths, labels=None, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.labels is not None:\n            return image, self.labels[idx]\n        return image\n\n# Model class\nclass PaddyModel(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=num_classes)\n        \n    def forward(self, x):\n        return self.model(x)\n\n# Data transformations\ndef get_transforms(is_train=True):\n    if is_train:\n        return transforms.Compose([\n            transforms.RandomResizedCrop(Config.IMAGE_SIZE),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(15),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    else:\n        return transforms.Compose([\n            transforms.Resize((Config.IMAGE_SIZE, Config.IMAGE_SIZE)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n\n# Training function\ndef train_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    for images, labels in tqdm(loader, desc='Training'):\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n    \n    return total_loss/len(loader), 100.*correct/total\n\n# Validation function\n@torch.no_grad()\ndef validate(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    for images, labels in tqdm(loader, desc='Validation'):\n        images, labels = images.to(device), labels.to(device)\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        total_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n    \n    return total_loss/len(loader), 100.*correct/total\n\ndef main():\n    print(f\"Using device: {Config.DEVICE}\")\n    \n    # Prepare data\n    all_images = []\n    labels = []\n    class_map = {}\n    \n    # Load training data\n    for idx, class_name in enumerate(sorted(os.listdir(Config.TRAIN_PATH))):\n        class_path = os.path.join(Config.TRAIN_PATH, class_name)\n        class_map[class_name] = idx\n        for img_name in os.listdir(class_path):\n            img_path = os.path.join(class_path, img_name)\n            all_images.append(img_path)\n            labels.append(idx)\n    \n    # Split data\n    X_train, X_val, y_train, y_val = train_test_split(\n        all_images, labels, test_size=0.2, stratify=labels, random_state=42\n    )\n    \n    # Create datasets\n    train_dataset = PaddyDataset(X_train, y_train, get_transforms(is_train=True))\n    val_dataset = PaddyDataset(X_val, y_val, get_transforms(is_train=False))\n    \n    # Create dataloaders\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=Config.BATCH_SIZE,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=Config.BATCH_SIZE,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    # Initialize model\n    model = PaddyModel(Config.NUM_CLASSES).to(Config.DEVICE)\n    \n    # Loss and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=Config.LEARNING_RATE,\n        weight_decay=Config.WEIGHT_DECAY\n    )\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.EPOCHS)\n    \n    # Training loop\n    best_val_acc = 0\n    \n    for epoch in range(Config.EPOCHS):\n        print(f\"\\nEpoch {epoch+1}/{Config.EPOCHS}\")\n        \n        train_loss, train_acc = train_epoch(\n            model, train_loader, criterion, optimizer, Config.DEVICE\n        )\n        \n        val_loss, val_acc = validate(\n            model, val_loader, criterion, Config.DEVICE\n        )\n        \n        scheduler.step()\n        \n        print(f\"Train Loss: {train_loss:.4f} Train Acc: {train_acc:.2f}%\")\n        print(f\"Val Loss: {val_loss:.4f} Val Acc: {val_acc:.2f}%\")\n        \n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(f\"Saved best model with validation accuracy: {val_acc:.2f}%\")\n    \n    # Prepare submission\n    model.load_state_dict(torch.load('best_model.pth'))\n    test_images = sorted([\n        os.path.join(Config.TEST_PATH, img_name)\n        for img_name in os.listdir(Config.TEST_PATH)\n    ])\n    \n    test_dataset = PaddyDataset(test_images, transform=get_transforms(is_train=False))\n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=Config.BATCH_SIZE,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n    \n    # Make predictions\n    model.eval()\n    predictions = []\n    image_ids = []\n    \n    with torch.no_grad():\n        for images in tqdm(test_loader, desc='Predicting'):\n            images = images.to(Config.DEVICE)\n            outputs = model(images)\n            _, preds = outputs.max(1)\n            predictions.extend(preds.cpu().numpy())\n    \n    # Create submission file\n    rev_class_map = {v: k for k, v in class_map.items()}\n    submission = pd.DataFrame({\n        'image_id': [os.path.basename(img_path) for img_path in test_images],\n        'label': [rev_class_map[pred] for pred in predictions]\n    })\n    \n    submission.to_csv('submission.csv', index=False)\n    print(\"Submission file created!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T05:09:08.833980Z","iopub.execute_input":"2025-03-03T05:09:08.834288Z","iopub.status.idle":"2025-03-03T07:09:56.012500Z","shell.execute_reply.started":"2025-03-03T05:09:08.834261Z","shell.execute_reply":"2025-03-03T07:09:56.011536Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:29<00:00,  1.26s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.7840 Train Acc: 38.57%\nVal Loss: 1.3885 Val Acc: 54.03%\nSaved best model with validation accuracy: 54.03%\n\nEpoch 2/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.1801 Train Acc: 60.46%\nVal Loss: 0.8540 Val Acc: 71.18%\nSaved best model with validation accuracy: 71.18%\n\nEpoch 3/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9548 Train Acc: 68.05%\nVal Loss: 0.7508 Val Acc: 74.78%\nSaved best model with validation accuracy: 74.78%\n\nEpoch 4/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:29<00:00,  1.26s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8266 Train Acc: 72.96%\nVal Loss: 0.7126 Val Acc: 75.98%\nSaved best model with validation accuracy: 75.98%\n\nEpoch 5/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7056 Train Acc: 76.47%\nVal Loss: 0.8521 Val Acc: 74.35%\n\nEpoch 6/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6189 Train Acc: 79.51%\nVal Loss: 0.5982 Val Acc: 80.36%\nSaved best model with validation accuracy: 80.36%\n\nEpoch 7/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5534 Train Acc: 81.53%\nVal Loss: 0.4729 Val Acc: 84.82%\nSaved best model with validation accuracy: 84.82%\n\nEpoch 8/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4701 Train Acc: 84.54%\nVal Loss: 0.3653 Val Acc: 88.09%\nSaved best model with validation accuracy: 88.09%\n\nEpoch 9/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4072 Train Acc: 86.77%\nVal Loss: 0.3230 Val Acc: 90.06%\nSaved best model with validation accuracy: 90.06%\n\nEpoch 10/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3673 Train Acc: 88.05%\nVal Loss: 0.2936 Val Acc: 90.87%\nSaved best model with validation accuracy: 90.87%\n\nEpoch 11/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:31<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3245 Train Acc: 89.02%\nVal Loss: 0.3048 Val Acc: 90.44%\n\nEpoch 12/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2819 Train Acc: 90.74%\nVal Loss: 0.2460 Val Acc: 91.69%\nSaved best model with validation accuracy: 91.69%\n\nEpoch 13/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2401 Train Acc: 91.83%\nVal Loss: 0.2070 Val Acc: 94.09%\nSaved best model with validation accuracy: 94.09%\n\nEpoch 14/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:31<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1978 Train Acc: 93.35%\nVal Loss: 0.1875 Val Acc: 94.96%\nSaved best model with validation accuracy: 94.96%\n\nEpoch 15/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:30<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1852 Train Acc: 93.72%\nVal Loss: 0.1614 Val Acc: 94.96%\n\nEpoch 16/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:32<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1571 Train Acc: 94.53%\nVal Loss: 0.1472 Val Acc: 95.34%\nSaved best model with validation accuracy: 95.34%\n\nEpoch 17/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:31<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1389 Train Acc: 94.97%\nVal Loss: 0.1451 Val Acc: 95.82%\nSaved best model with validation accuracy: 95.82%\n\nEpoch 18/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:31<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1343 Train Acc: 95.56%\nVal Loss: 0.1388 Val Acc: 96.35%\nSaved best model with validation accuracy: 96.35%\n\nEpoch 19/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:31<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1149 Train Acc: 95.88%\nVal Loss: 0.1298 Val Acc: 96.54%\nSaved best model with validation accuracy: 96.54%\n\nEpoch 20/20\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 261/261 [05:31<00:00,  1.27s/it]\nValidation: 100%|██████████| 66/66 [00:28<00:00,  2.33it/s]\n<ipython-input-3-6d4dcce7805b>:199: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('best_model.pth'))\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1155 Train Acc: 96.12%\nVal Loss: 0.1308 Val Acc: 96.49%\n","output_type":"stream"},{"name":"stderr","text":"Predicting: 100%|██████████| 109/109 [00:47<00:00,  2.29it/s]","output_type":"stream"},{"name":"stdout","text":"Submission file created!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}